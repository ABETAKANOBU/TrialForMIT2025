{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyDenseLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        \n",
    "        # 重みとバイアスの初期化\n",
    "        self.W = nn.Parameter(torch.randn(input_dim, output_dim, requires_grad=True))\n",
    "        self.b = nn.Parameter(torch.randn(1, output_dim, requires_grad=True))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "\n",
    "        # 線形変換を実行: z = inputs × W + b\n",
    "        z = torch.matmul(inputs, self.W) + self.b\n",
    "\n",
    "        # 活性化関数(sigmoid)を通す\n",
    "        output = torch.sigmoid(z)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Linear(in_features = m, out_features = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m：この層に入ってくるデータの次元（入力特徴量の数）\n",
    "# n：この層の出力の次元（出力ユニット数）\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(m,n),\n",
    "    nn.Relu(),\n",
    "    nn.reniar(n,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 順番に層を積み重ねるモデル（Sequential）を定義\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(m, n1),  # 入力層 → 第1層（入力次元 m → 出力次元 n1）\n",
    "    nn.ReLU(),         # 活性化関数ReLU（非線形変換）\n",
    "\n",
    "    # 中間層を追加する場合\n",
    "    # nn.Linear(n1, n2),\n",
    "    # nn.ReLU(),の形\n",
    "\n",
    "    nn.ReLU(),         # ReLU（再び非線形活性化）\n",
    "    nn.Linear(nK, 2)   # 最終出力層（入力次元 nK → 出力次元 2） → 例: 2クラス分類\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "loss = F.mse_loss(predicted, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期の重み（ランダムな値）を定義\n",
    "weights = tf.Variable([tf.random.normal(())])\n",
    "\n",
    "# 学習率（learning rate）を設定\n",
    "lr = 0.01  # 学習率は0.01（必要に応じて調整可能）\n",
    "\n",
    "# 無限ループ（学習を繰り返す）\n",
    "while True:  # 永遠にループ\n",
    "    # 自動微分のための記録を開始\n",
    "    with tf.GradientTape() as g:\n",
    "        # 損失（ロス）を計算する\n",
    "        loss = compute_loss(weights)  # compute_lossは別で定義されている関数\n",
    "        \n",
    "        # 損失に対する重みの勾配を計算\n",
    "        gradient = g.gradient(loss, weights)\n",
    "\n",
    "    # 勾配降下法によって重みを更新\n",
    "    weights = weights - lr * gradient"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forcompe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
